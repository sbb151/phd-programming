{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual Analysis using Dictionaries\n",
    "\n",
    "One of the basic ways to capture the content of a document is to count the *relative frequency of particular words* in the document. For instance, to determine how optimistic/pessimistic a given text is, researchers often use dictionaries of *positive* and *negative* words. Similar techniques can be used to determine risk and uncertainty of disclosures, financial focus of disclosures, focus on corporate social responsibility, non-GAAP reporting, etc.\n",
    "\n",
    "An alternative to a dictionary-based textual analysis would be to use a machine-learning algorithm which 'learns' text classifications from manually-coded pieces of text. However, since simple dictionary-based approaches often perform as well as more complex machine-learning algorithms ([Henry and Leone 2016](https://doi.org/10.2308/accr-51161)), we will focus our tutorial on how to use dictionaries to analyze texts.\n",
    "\n",
    "There are many different dictionaries for content analysis. For example:\n",
    "<br>\n",
    "\\- general and domain-specific dictionaries for tone/sentiment analysis\n",
    "<br>\n",
    "http://www.wjh.harvard.edu/~inquirer/homecat.htm\n",
    "<br>\n",
    "https://sraf.nd.edu/textual-analysis/resources/#LM%20Sentiment%20Word%20Lists\n",
    "<br>\n",
    "\\- corporate social responsibility dictionary\n",
    "<br>\n",
    "https://www.springer.com/us/book/9783319105352\n",
    "<br>\n",
    "\\- dictionary of accounting terms\n",
    "<br>\n",
    "http://www.oxfordreference.com/view/10.1093/acref/9780199563050.001.0001/acref-9780199563050\n",
    "\n",
    "Depending on your research question, you can always construct your own dictionary (e.g., dictionary of specific accounting terms that identify non-GAAP reporting).\n",
    "\n",
    "The following academic papers provide some examples of dictionary-based content analysis in accounting and finance:\n",
    "\n",
    "\\- tone/sentiment analysis using *binary* dictionaries of positive and negative words: [Henry 2008](https://doi.org/10.1177/0021943608319388); [Loughran and McDonald 2011](https://doi.org/10.1111/j.1540-6261.2010.01625.x); [Tetlock 2007](https://doi.org/10.1111/j.1540-6261.2007.01232.x);\n",
    "<br>\n",
    "\\- tone/sentiment analysis using *extremity rankings* of positive and negative words: [Bochkay, Chava, and Hales 2018](http://dx.doi.org/10.2139/ssrn.2781784);\n",
    "<br>\n",
    "\\- analysis of *topical content* of disclosures (e.g., product market, corporate strategy, corporate governance, marketing, etc.): [Hanley and Hoberg 2010](https://doi.org/10.1093/rfs/hhq024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclosure Tone\n",
    "Assume we want to calculate *Tone* of a company's earnings conference call, i.e., to what extent the earnings call exhibits optimistic vs. pessimistic views. Before writing your code, you have to make several design choices:\n",
    "\n",
    "**1\\)** <font color='blue'>Select a dictionary for sentiment analysis and clearly understand how this dictionary was constructed.</font> Some dictionaries contain only root words (e.g., increase, decrease), whereas others contain both root words and their word families (e.g., increase, increasing, increased, increases, etc). Some dictionaries also contain phrases in addition to individual words.\n",
    "\n",
    "If the selected dictionary contains only root words then you have to perform *stemming* of your documents.\n",
    "<br>\n",
    "*Stemming* is the process of reducing inflected (or sometimes derived) words to their word base or root. More information about stemming in Python can be found at: \n",
    "<br>\n",
    "https://www.datacamp.com/community/tutorials/stemming-lemmatization-python. \n",
    "\n",
    "Also, you will have to understand the format in which words are recorded in the dictionary file - Is each word recorded in a separate line? Do you have any other information in the dictionary besides words? We strongly recommend you to work with files in .txt format, either tab delimited or comma separated.\n",
    "\n",
    "**2\\)** <font color='blue'>Determine if every word count will be equally-weighted or not.</font>\n",
    "    <br>\n",
    "    Equally-weighed *Tone* measure is calculated as follows:\n",
    "  <font color='red'>\n",
    "  <br>\n",
    "    $$ Tone = \\frac{Positive Word Count - Negative Word Count}{Total Word Count} $$ \n",
    " <br>\n",
    "    </font>\n",
    " A popular alternative to equal-weighting of all word counts is to weight each word count by its document frequency. \n",
    " \n",
    "Specifically, inverse document frequency of a word $i$, <font color='green'> $idf_i = log(\\frac{\\text{Number of Documents in the Sample}}{\\text{Number of Documents Containing a word $i$}})$</font>, penalizes commonly-used words and assigns a higher weight to less common words.\n",
    "\n",
    "With $idf$, *Tone* of a document is calculated as follows:\n",
    "<br>\n",
    "<font color='red'>\n",
    "    $$ Tone = \\frac{\\sum_i PositiveWordCount_i \\times idf_i - \\sum_j NegativeWordCount_j \\times idf_j}{Total Word Count} $$ \n",
    " <br>\n",
    "</font>\n",
    "\n",
    "More information about word weightings can be found at:\n",
    "<br>\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html\n",
    "\n",
    "**3\\)** <font color='blue'>Determine how you will be dealing with negators (e.g., not bad, not good, did not increase).</font> You have several options:\n",
    "<br>\n",
    "\\- ignore that a positive/negative word can be negated. However, your reviewer will likely pick up on that;\n",
    "<br>\n",
    "\\- create a Regex to check for the presence of negators in front of positive and negative words. \n",
    "\n",
    "If a negator is present, then you can simply reverse the sentiment of the word next to the negator. For example:\n",
    "<br>\n",
    "\"our performance was not *bad*\" -1 (original) $\\rightarrow$ +1 (new), indicating that \"not bad\" has a positive sentiment.  \n",
    "\"our performance was not *good*\" +1 (original) $\\rightarrow$ -1 (new), indicating that \"not good\" has a negative sentiment. \n",
    "\n",
    "Alternatively, you can assign a new weight to a negated word in some *systematic* fashion. For example, you can assign 0.5 x original sentiment score to all negated words.\n",
    "\n",
    "Here is a list of negators you might want to consider in your regex:\n",
    "<br>\n",
    "<font color='green'>\n",
    "*not, never, no, none, nobody, nothing, don't, doesn't, won't, shan't, didn't, shouldn't, wouldn't, couldn't, can't, cannot, neither, nor*\n",
    "    </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Let us start with a simple tone analysis, where each word is equally-weighted and we do not account for negators\n",
    "# First, we need to load our dictionary files\n",
    "positive_words_dict = r\"./dictionaries/LM_Positive.txt\" # file path (location) to a text file with positive words\n",
    "negative_words_dict = r\"./dictionaries/LM_Negative.txt\" # file path to a text file with negative words\n",
    "\n",
    "# To be able to match all positive and negative words in dictionaries, we need to create a list of regular expressions corresponding to these words.\n",
    "# So, we need to write a function that will read all dictionary terms line-by-line and convert them to a dictionary of Regexes\n",
    "\n",
    "def create_dict_regex_list(dict_file:str):\n",
    "    \"\"\"Creates a list of regex expressions of dictionary terms.\"\"\" # function description (optional)\n",
    "    with open(dict_file,\"r\") as file:  # opens the specified dict_file in \"r\" (read) mode \n",
    "        dict_terms = file.read().splitlines() # reads the content of the file line-by-line and creates a list of extracted content\n",
    "    dict_terms_regex = [re.compile(r'\\b' + term + r'\\b', re.I) for term in dict_terms] \n",
    "    # re.compile(pattern) in Python compiles a regular expression pattern, which can be used for matching using its re.search, re.findall, etc.\n",
    "    # by adding \"\\b\" (i.e., boundary) on each side of the dictionary term in Regex, we specify an exact match of each dictionary term \n",
    "    return dict_terms_regex # specifies the output of the function - in our case, a list of Regex expressions\n",
    "\n",
    "# Now we can apply our function to create Regex lists for positive and negative dictionary terms\n",
    "positive_dict_regex = create_dict_regex_list(positive_words_dict)\n",
    "negative_dict_regex = create_dict_regex_list(negative_words_dict)\n",
    "print(positive_dict_regex[0:3])\n",
    "print(negative_dict_regex[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to write a function that will count positive, negative and all words in a given text.\n",
    "# Tone = (PositiveWordCount - NegativeWordCount)/TotalWordCount\n",
    "\n",
    "def get_tone (input_text:str):\n",
    "    \"\"\"Counts All and Specific Words in Text\"\"\" # function description (optional)\n",
    "    \n",
    "    ### Positive Words ###\n",
    "    \n",
    "    positive_words_matches = [re.findall(regex, input_text) for regex in positive_dict_regex] \n",
    "    # output of this search will be of the following format: [['able'], [], ['accomplish','accomplish'], [], ... ]\n",
    "    \n",
    "    positive_words_counts = [len(match) for match in positive_words_matches]\n",
    "    # output of this list transformation will be of the following format: [1, 0, 2, 0, ...]\n",
    "    \n",
    "    positive_words_sum = sum(positive_words_counts) # add all positive word counts\n",
    "    \n",
    "    ### Negative Words ###\n",
    "    \n",
    "    # now we can perform the same word counts for negative words\n",
    "    negative_words_matches = [re.findall(regex, input_text) for regex in negative_dict_regex]\n",
    "    negative_words_counts = [len(match) for match in negative_words_matches]\n",
    "    negative_words_sum = sum(negative_words_counts) # add all negative word counts\n",
    "    \n",
    "    ### Total Words ###\n",
    "    total_words = re.findall(r'\\b[a-zA-Z\\'\\-]+\\b', input_text) # searches for all words in text, allowing apostrophes and hyphens in words, e.g., company's, state-of-the-art\n",
    "    total_words_count = len(total_words) # calculates the number of all words in a given text\n",
    "    \n",
    "    # Finally, we can calculate Tone (expressed in % terms):\n",
    "    tone = 100 * (positive_words_sum - negative_words_sum)/total_words_count\n",
    "    \n",
    "    return (total_words_count, positive_words_sum, negative_words_sum, tone)\n",
    "    \n",
    "# Running our count_words function:\n",
    "counts = get_tone(\"As our volumes and revenues demonstrate, FedEx is experiencing strong growth in the US, where the economy remains solid. However, our international business, especially in Europe, weakened significantly since we last talked with you during our earnings call in September. In addition, China's economy has weakened due in part to trade disputes.  While international revenue was still growing, it is not growing at the rate we expected because of the overall global economic uncertainty. As a result, we have lowered our fiscal 2019 earnings guidance and are accelerating actions to reduce costs given the uncertainty of global macroeconomic trends. We are highly confident that we will achieve the benefits expected with the acquisition of TNT Express, although we will not achieve our FedEx profit improvement goal in fiscal 2019. [...] Like the rapid changes we have experienced, I'm confident that we will see improved operating earnings, margins and cash flow in FY '20 versus FY '19.\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To account for negators we have to keep track of negated words. Therefore, we need to update our Regex expressions:\n",
    "\n",
    "def create_dict_regex_list_with_negators(dict_file:str):\n",
    "    \"\"\"Creates a list of regex expressions of dictionary terms.\"\"\"\n",
    "    with open(dict_file,\"r\") as file: \n",
    "        dict_terms = file.read().splitlines() \n",
    "    dict_terms_regex =[re.compile(r'(not|never|no|none|nobody|nothing|don\\'t|doesn\\'t|won\\'t|shan\\'t|didn\\'t|shouldn\\'t|wouldn\\'t|couldn\\'t|can\\'t|cannot|neither|nor)?\\s(' + term + r')\\b', re.I) for term in dict_terms] \n",
    "    return dict_terms_regex \n",
    "\n",
    "# Now we can apply our function to create Regex lists for positive and negative dictionary terms\n",
    "positive_dict_regex = create_dict_regex_list_with_negators(positive_words_dict)\n",
    "negative_dict_regex = create_dict_regex_list_with_negators(negative_words_dict)\n",
    "\n",
    "print(positive_dict_regex[0])\n",
    "print(negative_dict_regex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count words version 2, accounting for negators\n",
    "def get_tone2 (input_text:str):\n",
    "    \"\"\"Counts All and Specific Words in Text, accounting for negators\"\"\" # function description (optional)\n",
    "    \n",
    "    total_words = re.findall(r'\\b[a-zA-Z\\'\\-]+\\b', input_text) # find all words in text\n",
    "    total_words_count = len(total_words) # calculate the number of total words\n",
    "    \n",
    "    # To account for negators, let's create two separate counts for positive and negated positive words\n",
    "    \n",
    "    positive_word_count = 0 # initial values\n",
    "    negated_positive_word_count = 0 # initial values\n",
    "    \n",
    "    for regex in positive_dict_regex:\n",
    "        matches = re.findall(regex, input_text) # searches for all occurences of Regex\n",
    "        for match in matches:\n",
    "            if len(match)>0: # if the match is not empty\n",
    "                print(match) # just to check the match output\n",
    "                \n",
    "            if match[0] == '':\n",
    "                positive_word_count += 1 \n",
    "            else:\n",
    "                negated_positive_word_count += 1\n",
    "                \n",
    "   # If we are just shifting the sentiment of negated positive words, then the final positive word count is just:\n",
    "    positive_words_sum = positive_word_count # i.e., count without negators\n",
    "    \n",
    "### Repeat the same for negative words:\n",
    "    negative_word_count = 0 # initial values\n",
    "    negated_negative_word_count = 0 # initial values\n",
    "    \n",
    "    for regex in negative_dict_regex:\n",
    "        matches = re.findall(regex, input_text) # search for all occurences of Regex\n",
    "        for match in matches:\n",
    "            if len(match)>0: # if the match is not empty\n",
    "                print(match) # just to check the match output         \n",
    "            if match[0] == '':\n",
    "                negative_word_count += 1 \n",
    "            else:\n",
    "                negated_negative_word_count += 1\n",
    "                \n",
    "   # If we are just shifting the sentiment of negated negative words, then the final negative word count is just:\n",
    "    negative_words_sum = negative_word_count # i.e., count without negators\n",
    "    \n",
    "    # Then, Tone is:\n",
    "    tone = 100 * (positive_words_sum - negative_words_sum)/total_words_count\n",
    "    \n",
    "    return (total_words_count, positive_words_sum, negative_words_sum, tone)\n",
    "\n",
    "# Running our count_words2 function:\n",
    "counts = get_tone2(\"As our volumes and revenues demonstrate, FedEx is experiencing strong growth in the US, where the economy remains solid. However, our international business, especially in Europe, weakened significantly since we last talked with you during our earnings call in September. In addition, China's economy has weakened due in part to trade disputes.  While international revenue was still growing, it is not growing at the rate we expected because of the overall global economic uncertainty. As a result, we have lowered our fiscal 2019 earnings guidance and are accelerating actions to reduce costs given the uncertainty of global macroeconomic trends. We are highly confident that we will achieve the benefits expected with the acquisition of TNT Express, although we will not achieve our FedEx profit improvement goal in fiscal 2019. [...] Like the rapid changes we have experienced, I'm confident that we will see improved operating earnings, margins and cash flow in FY '20 versus FY '19.\")\n",
    "\n",
    "print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
